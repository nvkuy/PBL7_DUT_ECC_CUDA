//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-31833905
// Cuda compilation tools, release 11.8, V11.8.89
// Based on NVVM 7.0.1
//

.version 7.8
.target sm_86
.address_size 64

	// .globl	_Z3fntPjS_jjjS_S_S_j
.weak .global .align 8 .b8 _ZTVSt9exception[40];
.weak .global .align 8 .b8 _ZTVSt9bad_alloc[40];
.weak .global .align 8 .b8 _ZTVSt20bad_array_new_length[40];
.weak .global .align 8 .b8 _ZTVSt13runtime_error[40];
.weak .global .align 8 .b8 _ZTVSt13_System_error[40];
.weak .global .align 8 .b8 _ZTVSt12system_error[40];
.weak .global .align 8 .b8 _ZTVSt25_Iostream_error_category2[72];
.weak .global .align 8 .b8 _ZTVSt8bad_cast[40];
.weak .global .align 8 .b8 _ZTVSt11_Facet_base[48];
.weak .global .align 8 .b8 _ZTVNSt6locale5facetE[48];
.weak .global .align 8 .b8 _ZTVSt10ctype_base[48];
.weak .global .align 8 .b8 _ZTVSt5ctypeIcE[112];
.weak .global .align 8 .b8 _ZTVNSt8ios_base7failureE[40];
.weak .global .align 8 .b8 _ZTVSt7num_putIcSt19ostreambuf_iteratorIcSt11char_traitsIcEEE[112];

.visible .entry _Z3fntPjS_jjjS_S_S_j(
	.param .u64 _Z3fntPjS_jjjS_S_S_j_param_0,
	.param .u64 _Z3fntPjS_jjjS_S_S_j_param_1,
	.param .u32 _Z3fntPjS_jjjS_S_S_j_param_2,
	.param .u32 _Z3fntPjS_jjjS_S_S_j_param_3,
	.param .u32 _Z3fntPjS_jjjS_S_S_j_param_4,
	.param .u64 _Z3fntPjS_jjjS_S_S_j_param_5,
	.param .u64 _Z3fntPjS_jjjS_S_S_j_param_6,
	.param .u64 _Z3fntPjS_jjjS_S_S_j_param_7,
	.param .u32 _Z3fntPjS_jjjS_S_S_j_param_8
)
{
	.reg .pred 	%p<88>;
	.reg .b32 	%r<429>;
	.reg .b64 	%rd<227>;


	ld.param.u64 	%rd31, [_Z3fntPjS_jjjS_S_S_j_param_0];
	ld.param.u64 	%rd32, [_Z3fntPjS_jjjS_S_S_j_param_1];
	ld.param.u32 	%r137, [_Z3fntPjS_jjjS_S_S_j_param_2];
	ld.param.u32 	%r138, [_Z3fntPjS_jjjS_S_S_j_param_3];
	ld.param.u32 	%r139, [_Z3fntPjS_jjjS_S_S_j_param_4];
	ld.param.u64 	%rd33, [_Z3fntPjS_jjjS_S_S_j_param_5];
	ld.param.u64 	%rd34, [_Z3fntPjS_jjjS_S_S_j_param_6];
	ld.param.u64 	%rd30, [_Z3fntPjS_jjjS_S_S_j_param_7];
	ld.param.u32 	%r140, [_Z3fntPjS_jjjS_S_S_j_param_8];
	cvta.to.global.u64 	%rd1, %rd33;
	cvta.to.global.u64 	%rd2, %rd31;
	cvta.to.global.u64 	%rd3, %rd34;
	cvta.to.global.u64 	%rd4, %rd32;
	mov.u32 	%r141, %ntid.x;
	mov.u32 	%r142, %ctaid.x;
	mov.u32 	%r143, %tid.x;
	mad.lo.s32 	%r144, %r142, %r141, %r143;
	mov.u32 	%r145, 1;
	shl.b32 	%r1, %r145, %r137;
	shl.b32 	%r2, %r145, %r138;
	add.s32 	%r3, %r2, -1;
	mul.lo.s32 	%r4, %r144, %r140;
	add.s32 	%r146, %r4, %r140;
	shr.u32 	%r5, %r2, 1;
	min.u32 	%r6, %r146, %r5;
	setp.le.u32 	%p1, %r6, %r4;
	@%p1 bra 	$L__BB0_34;

	setp.eq.s32 	%p2, %r137, %r138;
	add.s32 	%r7, %r5, %r3;
	mov.u32 	%r147, -2;
	sub.s32 	%r148, %r147, %r4;
	not.b32 	%r149, %r6;
	sub.s32 	%r8, %r148, %r149;
	sub.s32 	%r150, %r6, %r4;
	and.b32  	%r396, %r150, 3;
	@%p2 bra 	$L__BB0_18;
	bra.uni 	$L__BB0_2;

$L__BB0_18:
	setp.eq.s32 	%p12, %r396, 0;
	mov.u32 	%r401, %r4;
	@%p12 bra 	$L__BB0_23;

	mov.u32 	%r401, %r4;

$L__BB0_20:
	.pragma "nounroll";
	setp.ge.u32 	%p13, %r401, %r1;
	@%p13 bra 	$L__BB0_22;

	mul.wide.u32 	%rd65, %r401, 4;
	add.s64 	%rd66, %rd2, %rd65;
	ld.global.u32 	%r166, [%rd66];
	add.s32 	%r167, %r401, %r3;
	mul.wide.u32 	%rd67, %r167, 4;
	add.s64 	%rd68, %rd1, %rd67;
	ld.global.u32 	%r168, [%rd68];
	mul.wide.u32 	%rd69, %r168, 4;
	add.s64 	%rd70, %rd4, %rd69;
	st.global.u32 	[%rd70], %r166;

$L__BB0_22:
	add.s32 	%r169, %r401, %r5;
	mul.wide.u32 	%rd71, %r169, 4;
	add.s64 	%rd72, %rd2, %rd71;
	ld.global.u32 	%r170, [%rd72];
	add.s32 	%r171, %r7, %r401;
	mul.wide.u32 	%rd73, %r171, 4;
	add.s64 	%rd74, %rd1, %rd73;
	ld.global.u32 	%r172, [%rd74];
	mul.wide.u32 	%rd75, %r172, 4;
	add.s64 	%rd76, %rd4, %rd75;
	st.global.u32 	[%rd76], %r170;
	add.s32 	%r401, %r401, 1;
	add.s32 	%r396, %r396, -1;
	setp.ne.s32 	%p14, %r396, 0;
	@%p14 bra 	$L__BB0_20;

$L__BB0_23:
	setp.lt.u32 	%p15, %r8, 3;
	@%p15 bra 	$L__BB0_34;

$L__BB0_25:
	setp.ge.u32 	%p16, %r401, %r1;
	@%p16 bra 	$L__BB0_27;

	mul.wide.u32 	%rd77, %r401, 4;
	add.s64 	%rd78, %rd2, %rd77;
	ld.global.u32 	%r173, [%rd78];
	add.s32 	%r174, %r401, %r3;
	mul.wide.u32 	%rd79, %r174, 4;
	add.s64 	%rd80, %rd1, %rd79;
	ld.global.u32 	%r175, [%rd80];
	mul.wide.u32 	%rd81, %r175, 4;
	add.s64 	%rd82, %rd4, %rd81;
	st.global.u32 	[%rd82], %r173;

$L__BB0_27:
	add.s32 	%r176, %r401, %r5;
	mul.wide.u32 	%rd83, %r176, 4;
	add.s64 	%rd84, %rd2, %rd83;
	ld.global.u32 	%r177, [%rd84];
	add.s32 	%r178, %r7, %r401;
	mul.wide.u32 	%rd85, %r178, 4;
	add.s64 	%rd86, %rd1, %rd85;
	ld.global.u32 	%r179, [%rd86];
	mul.wide.u32 	%rd87, %r179, 4;
	add.s64 	%rd88, %rd4, %rd87;
	st.global.u32 	[%rd88], %r177;
	add.s32 	%r26, %r401, 1;
	setp.ge.u32 	%p17, %r26, %r1;
	@%p17 bra 	$L__BB0_29;

	mul.wide.u32 	%rd89, %r26, 4;
	add.s64 	%rd90, %rd2, %rd89;
	ld.global.u32 	%r180, [%rd90];
	add.s32 	%r181, %r401, %r2;
	mul.wide.u32 	%rd91, %r181, 4;
	add.s64 	%rd92, %rd1, %rd91;
	ld.global.u32 	%r182, [%rd92];
	mul.wide.u32 	%rd93, %r182, 4;
	add.s64 	%rd94, %rd4, %rd93;
	st.global.u32 	[%rd94], %r180;

$L__BB0_29:
	add.s32 	%r183, %r26, %r5;
	mul.wide.u32 	%rd95, %r183, 4;
	add.s64 	%rd96, %rd2, %rd95;
	ld.global.u32 	%r184, [%rd96];
	add.s32 	%r185, %r7, %r26;
	mul.wide.u32 	%rd97, %r185, 4;
	add.s64 	%rd98, %rd1, %rd97;
	ld.global.u32 	%r186, [%rd98];
	mul.wide.u32 	%rd99, %r186, 4;
	add.s64 	%rd100, %rd4, %rd99;
	st.global.u32 	[%rd100], %r184;
	add.s32 	%r27, %r401, 2;
	setp.ge.u32 	%p18, %r27, %r1;
	@%p18 bra 	$L__BB0_31;

	mul.wide.u32 	%rd101, %r27, 4;
	add.s64 	%rd102, %rd2, %rd101;
	ld.global.u32 	%r187, [%rd102];
	add.s32 	%r188, %r27, %r3;
	mul.wide.u32 	%rd103, %r188, 4;
	add.s64 	%rd104, %rd1, %rd103;
	ld.global.u32 	%r189, [%rd104];
	mul.wide.u32 	%rd105, %r189, 4;
	add.s64 	%rd106, %rd4, %rd105;
	st.global.u32 	[%rd106], %r187;

$L__BB0_31:
	add.s32 	%r190, %r27, %r5;
	mul.wide.u32 	%rd107, %r190, 4;
	add.s64 	%rd108, %rd2, %rd107;
	ld.global.u32 	%r191, [%rd108];
	add.s32 	%r192, %r7, %r27;
	mul.wide.u32 	%rd109, %r192, 4;
	add.s64 	%rd110, %rd1, %rd109;
	ld.global.u32 	%r193, [%rd110];
	mul.wide.u32 	%rd111, %r193, 4;
	add.s64 	%rd112, %rd4, %rd111;
	st.global.u32 	[%rd112], %r191;
	add.s32 	%r28, %r401, 3;
	setp.ge.u32 	%p19, %r28, %r1;
	@%p19 bra 	$L__BB0_33;

	mul.wide.u32 	%rd113, %r28, 4;
	add.s64 	%rd114, %rd2, %rd113;
	ld.global.u32 	%r194, [%rd114];
	add.s32 	%r195, %r28, %r3;
	mul.wide.u32 	%rd115, %r195, 4;
	add.s64 	%rd116, %rd1, %rd115;
	ld.global.u32 	%r196, [%rd116];
	mul.wide.u32 	%rd117, %r196, 4;
	add.s64 	%rd118, %rd4, %rd117;
	st.global.u32 	[%rd118], %r194;

$L__BB0_33:
	add.s32 	%r197, %r28, %r5;
	mul.wide.u32 	%rd119, %r197, 4;
	add.s64 	%rd120, %rd2, %rd119;
	ld.global.u32 	%r198, [%rd120];
	add.s32 	%r199, %r7, %r28;
	mul.wide.u32 	%rd121, %r199, 4;
	add.s64 	%rd122, %rd1, %rd121;
	ld.global.u32 	%r200, [%rd122];
	mul.wide.u32 	%rd123, %r200, 4;
	add.s64 	%rd124, %rd4, %rd123;
	st.global.u32 	[%rd124], %r198;
	add.s32 	%r401, %r401, 4;
	setp.lt.u32 	%p20, %r401, %r6;
	@%p20 bra 	$L__BB0_25;
	bra.uni 	$L__BB0_34;

$L__BB0_2:
	setp.eq.s32 	%p3, %r396, 0;
	mov.u32 	%r397, %r4;
	@%p3 bra 	$L__BB0_7;

	mov.u32 	%r397, %r4;

$L__BB0_4:
	.pragma "nounroll";
	setp.ge.u32 	%p4, %r397, %r1;
	@%p4 bra 	$L__BB0_6;

	mul.wide.u32 	%rd35, %r397, 4;
	add.s64 	%rd36, %rd2, %rd35;
	ld.global.u32 	%r151, [%rd36];
	add.s32 	%r152, %r397, %r3;
	mul.wide.u32 	%rd37, %r152, 4;
	add.s64 	%rd38, %rd1, %rd37;
	ld.global.u32 	%r153, [%rd38];
	mul.wide.u32 	%rd39, %r153, 4;
	add.s64 	%rd40, %rd4, %rd39;
	st.global.u32 	[%rd40], %r151;

$L__BB0_6:
	add.s32 	%r397, %r397, 1;
	add.s32 	%r396, %r396, -1;
	setp.ne.s32 	%p5, %r396, 0;
	@%p5 bra 	$L__BB0_4;

$L__BB0_7:
	setp.lt.u32 	%p6, %r8, 3;
	@%p6 bra 	$L__BB0_34;

$L__BB0_9:
	setp.ge.u32 	%p7, %r397, %r1;
	@%p7 bra 	$L__BB0_11;

	mul.wide.u32 	%rd41, %r397, 4;
	add.s64 	%rd42, %rd2, %rd41;
	ld.global.u32 	%r154, [%rd42];
	add.s32 	%r155, %r397, %r3;
	mul.wide.u32 	%rd43, %r155, 4;
	add.s64 	%rd44, %rd1, %rd43;
	ld.global.u32 	%r156, [%rd44];
	mul.wide.u32 	%rd45, %r156, 4;
	add.s64 	%rd46, %rd4, %rd45;
	st.global.u32 	[%rd46], %r154;

$L__BB0_11:
	add.s32 	%r16, %r397, 1;
	setp.ge.u32 	%p8, %r16, %r1;
	@%p8 bra 	$L__BB0_13;

	mul.wide.u32 	%rd47, %r16, 4;
	add.s64 	%rd48, %rd2, %rd47;
	ld.global.u32 	%r157, [%rd48];
	add.s32 	%r158, %r397, %r2;
	mul.wide.u32 	%rd49, %r158, 4;
	add.s64 	%rd50, %rd1, %rd49;
	ld.global.u32 	%r159, [%rd50];
	mul.wide.u32 	%rd51, %r159, 4;
	add.s64 	%rd52, %rd4, %rd51;
	st.global.u32 	[%rd52], %r157;

$L__BB0_13:
	add.s32 	%r17, %r397, 2;
	setp.ge.u32 	%p9, %r17, %r1;
	@%p9 bra 	$L__BB0_15;

	mul.wide.u32 	%rd53, %r17, 4;
	add.s64 	%rd54, %rd2, %rd53;
	ld.global.u32 	%r160, [%rd54];
	add.s32 	%r161, %r17, %r3;
	mul.wide.u32 	%rd55, %r161, 4;
	add.s64 	%rd56, %rd1, %rd55;
	ld.global.u32 	%r162, [%rd56];
	mul.wide.u32 	%rd57, %r162, 4;
	add.s64 	%rd58, %rd4, %rd57;
	st.global.u32 	[%rd58], %r160;

$L__BB0_15:
	add.s32 	%r18, %r397, 3;
	setp.ge.u32 	%p10, %r18, %r1;
	@%p10 bra 	$L__BB0_17;

	mul.wide.u32 	%rd59, %r18, 4;
	add.s64 	%rd60, %rd2, %rd59;
	ld.global.u32 	%r163, [%rd60];
	add.s32 	%r164, %r18, %r3;
	mul.wide.u32 	%rd61, %r164, 4;
	add.s64 	%rd62, %rd1, %rd61;
	ld.global.u32 	%r165, [%rd62];
	mul.wide.u32 	%rd63, %r165, 4;
	add.s64 	%rd64, %rd4, %rd63;
	st.global.u32 	[%rd64], %r163;

$L__BB0_17:
	add.s32 	%r397, %r397, 4;
	setp.lt.u32 	%p11, %r397, %r6;
	@%p11 bra 	$L__BB0_9;

$L__BB0_34:
	bar.sync 	0;
	setp.eq.s32 	%p21, %r138, 0;
	@%p21 bra 	$L__BB0_59;

	not.b32 	%r202, %r6;
	mov.u32 	%r203, -2;
	sub.s32 	%r204, %r203, %r4;
	sub.s32 	%r30, %r204, %r202;
	sub.s32 	%r205, %r6, %r4;
	and.b32  	%r31, %r205, 3;
	add.s32 	%r32, %r4, 1;
	add.s32 	%r33, %r4, 2;
	add.s32 	%r34, %r4, 3;
	and.b32  	%r206, %r139, 2;
	shr.u32 	%r207, %r206, 1;
	mul.lo.s32 	%r35, %r207, 65535;
	mov.u32 	%r403, 0;

$L__BB0_36:
	mov.u32 	%r36, %r403;
	mov.u32 	%r208, 1;
	shl.b32 	%r37, %r208, %r36;
	add.s32 	%r403, %r36, 1;
	@%p1 bra 	$L__BB0_58;

	setp.eq.s32 	%p23, %r31, 0;
	add.s32 	%r39, %r37, -1;
	add.s32 	%r40, %r39, %r35;
	mov.u32 	%r407, %r4;
	@%p23 bra 	$L__BB0_47;

	shr.u32 	%r210, %r4, %r36;
	shl.b32 	%r211, %r210, %r403;
	and.b32  	%r212, %r4, %r39;
	add.s32 	%r213, %r211, %r212;
	mul.wide.u32 	%rd125, %r213, 4;
	add.s64 	%rd5, %rd4, %rd125;
	ld.global.u32 	%r41, [%rd5];
	add.s32 	%r214, %r213, %r37;
	mul.wide.u32 	%rd126, %r214, 4;
	add.s64 	%rd6, %rd4, %rd126;
	add.s32 	%r215, %r40, %r212;
	mul.wide.u32 	%rd127, %r215, 4;
	add.s64 	%rd128, %rd3, %rd127;
	ld.global.u32 	%r42, [%rd6];
	setp.eq.s32 	%p24, %r42, 65536;
	ld.global.u32 	%r43, [%rd128];
	setp.eq.s32 	%p25, %r43, 65536;
	and.pred  	%p26, %p24, %p25;
	mov.u32 	%r404, 1;
	@%p26 bra 	$L__BB0_40;

	mul.lo.s32 	%r216, %r43, %r42;
	mul.wide.u32 	%rd129, %r216, -65535;
	shr.u64 	%rd130, %rd129, 48;
	cvt.u32.u64 	%r217, %rd130;
	mul.lo.s32 	%r218, %r217, 65537;
	sub.s32 	%r404, %r216, %r218;

$L__BB0_40:
	add.s32 	%r219, %r404, %r41;
	mul.wide.u32 	%rd131, %r219, -65535;
	shr.u64 	%rd132, %rd131, 48;
	cvt.u32.u64 	%r220, %rd132;
	mul.lo.s32 	%r221, %r220, 65537;
	sub.s32 	%r222, %r219, %r221;
	st.global.u32 	[%rd5], %r222;
	add.s32 	%r223, %r41, 65537;
	sub.s32 	%r224, %r223, %r404;
	mul.wide.u32 	%rd133, %r224, -65535;
	shr.u64 	%rd134, %rd133, 48;
	cvt.u32.u64 	%r225, %rd134;
	mul.lo.s32 	%r226, %r225, 65537;
	sub.s32 	%r227, %r224, %r226;
	st.global.u32 	[%rd6], %r227;
	setp.eq.s32 	%p27, %r31, 1;
	mov.u32 	%r407, %r32;
	@%p27 bra 	$L__BB0_47;

	shr.u32 	%r229, %r32, %r36;
	shl.b32 	%r230, %r229, %r403;
	and.b32  	%r231, %r32, %r39;
	add.s32 	%r232, %r230, %r231;
	mul.wide.u32 	%rd135, %r232, 4;
	add.s64 	%rd7, %rd4, %rd135;
	ld.global.u32 	%r46, [%rd7];
	add.s32 	%r233, %r232, %r37;
	mul.wide.u32 	%rd136, %r233, 4;
	add.s64 	%rd8, %rd4, %rd136;
	add.s32 	%r234, %r40, %r231;
	mul.wide.u32 	%rd137, %r234, 4;
	add.s64 	%rd138, %rd3, %rd137;
	ld.global.u32 	%r47, [%rd8];
	setp.eq.s32 	%p28, %r47, 65536;
	ld.global.u32 	%r48, [%rd138];
	setp.eq.s32 	%p29, %r48, 65536;
	and.pred  	%p30, %p28, %p29;
	mov.u32 	%r405, 1;
	@%p30 bra 	$L__BB0_43;

	mul.lo.s32 	%r235, %r48, %r47;
	mul.wide.u32 	%rd139, %r235, -65535;
	shr.u64 	%rd140, %rd139, 48;
	cvt.u32.u64 	%r236, %rd140;
	mul.lo.s32 	%r237, %r236, 65537;
	sub.s32 	%r405, %r235, %r237;

$L__BB0_43:
	add.s32 	%r238, %r405, %r46;
	mul.wide.u32 	%rd141, %r238, -65535;
	shr.u64 	%rd142, %rd141, 48;
	cvt.u32.u64 	%r239, %rd142;
	mul.lo.s32 	%r240, %r239, 65537;
	sub.s32 	%r241, %r238, %r240;
	st.global.u32 	[%rd7], %r241;
	add.s32 	%r242, %r46, 65537;
	sub.s32 	%r243, %r242, %r405;
	mul.wide.u32 	%rd143, %r243, -65535;
	shr.u64 	%rd144, %rd143, 48;
	cvt.u32.u64 	%r244, %rd144;
	mul.lo.s32 	%r245, %r244, 65537;
	sub.s32 	%r246, %r243, %r245;
	st.global.u32 	[%rd8], %r246;
	setp.eq.s32 	%p31, %r31, 2;
	mov.u32 	%r407, %r33;
	@%p31 bra 	$L__BB0_47;

	shr.u32 	%r248, %r33, %r36;
	shl.b32 	%r249, %r248, %r403;
	and.b32  	%r250, %r33, %r39;
	add.s32 	%r251, %r249, %r250;
	mul.wide.u32 	%rd145, %r251, 4;
	add.s64 	%rd9, %rd4, %rd145;
	ld.global.u32 	%r51, [%rd9];
	add.s32 	%r252, %r251, %r37;
	mul.wide.u32 	%rd146, %r252, 4;
	add.s64 	%rd10, %rd4, %rd146;
	add.s32 	%r253, %r40, %r250;
	mul.wide.u32 	%rd147, %r253, 4;
	add.s64 	%rd148, %rd3, %rd147;
	ld.global.u32 	%r52, [%rd10];
	setp.eq.s32 	%p32, %r52, 65536;
	ld.global.u32 	%r53, [%rd148];
	setp.eq.s32 	%p33, %r53, 65536;
	and.pred  	%p34, %p32, %p33;
	mov.u32 	%r406, 1;
	@%p34 bra 	$L__BB0_46;

	mul.lo.s32 	%r254, %r53, %r52;
	mul.wide.u32 	%rd149, %r254, -65535;
	shr.u64 	%rd150, %rd149, 48;
	cvt.u32.u64 	%r255, %rd150;
	mul.lo.s32 	%r256, %r255, 65537;
	sub.s32 	%r406, %r254, %r256;

$L__BB0_46:
	add.s32 	%r257, %r406, %r51;
	mul.wide.u32 	%rd151, %r257, -65535;
	shr.u64 	%rd152, %rd151, 48;
	cvt.u32.u64 	%r258, %rd152;
	mul.lo.s32 	%r259, %r258, 65537;
	sub.s32 	%r260, %r257, %r259;
	st.global.u32 	[%rd9], %r260;
	add.s32 	%r261, %r51, 65537;
	sub.s32 	%r262, %r261, %r406;
	mul.wide.u32 	%rd153, %r262, -65535;
	shr.u64 	%rd154, %rd153, 48;
	cvt.u32.u64 	%r263, %rd154;
	mul.lo.s32 	%r264, %r263, 65537;
	sub.s32 	%r265, %r262, %r264;
	st.global.u32 	[%rd10], %r265;
	mov.u32 	%r407, %r34;

$L__BB0_47:
	setp.lt.u32 	%p35, %r30, 3;
	@%p35 bra 	$L__BB0_58;

$L__BB0_49:
	shr.u32 	%r267, %r407, %r36;
	shl.b32 	%r268, %r267, %r403;
	and.b32  	%r269, %r407, %r39;
	add.s32 	%r270, %r268, %r269;
	mul.wide.u32 	%rd155, %r270, 4;
	add.s64 	%rd11, %rd4, %rd155;
	ld.global.u32 	%r58, [%rd11];
	add.s32 	%r271, %r270, %r37;
	mul.wide.u32 	%rd156, %r271, 4;
	add.s64 	%rd12, %rd4, %rd156;
	add.s32 	%r272, %r40, %r269;
	mul.wide.u32 	%rd157, %r272, 4;
	add.s64 	%rd158, %rd3, %rd157;
	ld.global.u32 	%r59, [%rd12];
	setp.eq.s32 	%p36, %r59, 65536;
	ld.global.u32 	%r60, [%rd158];
	setp.eq.s32 	%p37, %r60, 65536;
	and.pred  	%p38, %p36, %p37;
	mov.u32 	%r410, 1;
	mov.u32 	%r409, %r410;
	@%p38 bra 	$L__BB0_51;

	mul.lo.s32 	%r273, %r60, %r59;
	mul.wide.u32 	%rd159, %r273, -65535;
	shr.u64 	%rd160, %rd159, 48;
	cvt.u32.u64 	%r274, %rd160;
	mul.lo.s32 	%r275, %r274, 65537;
	sub.s32 	%r409, %r273, %r275;

$L__BB0_51:
	add.s32 	%r277, %r409, %r58;
	mul.wide.u32 	%rd161, %r277, -65535;
	shr.u64 	%rd162, %rd161, 48;
	cvt.u32.u64 	%r278, %rd162;
	mul.lo.s32 	%r279, %r278, 65537;
	sub.s32 	%r280, %r277, %r279;
	st.global.u32 	[%rd11], %r280;
	add.s32 	%r281, %r58, 65537;
	sub.s32 	%r282, %r281, %r409;
	mul.wide.u32 	%rd163, %r282, -65535;
	shr.u64 	%rd164, %rd163, 48;
	cvt.u32.u64 	%r283, %rd164;
	mul.lo.s32 	%r284, %r283, 65537;
	sub.s32 	%r285, %r282, %r284;
	st.global.u32 	[%rd12], %r285;
	add.s32 	%r63, %r407, 1;
	shr.u32 	%r286, %r63, %r36;
	shl.b32 	%r287, %r286, %r403;
	and.b32  	%r288, %r63, %r39;
	add.s32 	%r289, %r287, %r288;
	mul.wide.u32 	%rd165, %r289, 4;
	add.s64 	%rd13, %rd4, %rd165;
	ld.global.u32 	%r64, [%rd13];
	add.s32 	%r290, %r289, %r37;
	mul.wide.u32 	%rd166, %r290, 4;
	add.s64 	%rd14, %rd4, %rd166;
	add.s32 	%r291, %r40, %r288;
	mul.wide.u32 	%rd167, %r291, 4;
	add.s64 	%rd168, %rd3, %rd167;
	ld.global.u32 	%r65, [%rd14];
	setp.eq.s32 	%p39, %r65, 65536;
	ld.global.u32 	%r66, [%rd168];
	setp.eq.s32 	%p40, %r66, 65536;
	and.pred  	%p41, %p39, %p40;
	@%p41 bra 	$L__BB0_53;

	mul.lo.s32 	%r292, %r66, %r65;
	mul.wide.u32 	%rd169, %r292, -65535;
	shr.u64 	%rd170, %rd169, 48;
	cvt.u32.u64 	%r293, %rd170;
	mul.lo.s32 	%r294, %r293, 65537;
	sub.s32 	%r410, %r292, %r294;

$L__BB0_53:
	add.s32 	%r296, %r410, %r64;
	mul.wide.u32 	%rd171, %r296, -65535;
	shr.u64 	%rd172, %rd171, 48;
	cvt.u32.u64 	%r297, %rd172;
	mul.lo.s32 	%r298, %r297, 65537;
	sub.s32 	%r299, %r296, %r298;
	st.global.u32 	[%rd13], %r299;
	add.s32 	%r300, %r64, 65537;
	sub.s32 	%r301, %r300, %r410;
	mul.wide.u32 	%rd173, %r301, -65535;
	shr.u64 	%rd174, %rd173, 48;
	cvt.u32.u64 	%r302, %rd174;
	mul.lo.s32 	%r303, %r302, 65537;
	sub.s32 	%r304, %r301, %r303;
	st.global.u32 	[%rd14], %r304;
	add.s32 	%r69, %r63, 1;
	mov.u32 	%r412, 1;
	shr.u32 	%r305, %r69, %r36;
	shl.b32 	%r306, %r305, %r403;
	and.b32  	%r307, %r69, %r39;
	add.s32 	%r308, %r306, %r307;
	mul.wide.u32 	%rd175, %r308, 4;
	add.s64 	%rd15, %rd4, %rd175;
	ld.global.u32 	%r70, [%rd15];
	add.s32 	%r309, %r308, %r37;
	mul.wide.u32 	%rd176, %r309, 4;
	add.s64 	%rd16, %rd4, %rd176;
	add.s32 	%r310, %r40, %r307;
	mul.wide.u32 	%rd177, %r310, 4;
	add.s64 	%rd178, %rd3, %rd177;
	ld.global.u32 	%r71, [%rd16];
	setp.eq.s32 	%p42, %r71, 65536;
	ld.global.u32 	%r72, [%rd178];
	setp.eq.s32 	%p43, %r72, 65536;
	and.pred  	%p44, %p42, %p43;
	mov.u32 	%r411, %r412;
	@%p44 bra 	$L__BB0_55;

	mul.lo.s32 	%r311, %r72, %r71;
	mul.wide.u32 	%rd179, %r311, -65535;
	shr.u64 	%rd180, %rd179, 48;
	cvt.u32.u64 	%r312, %rd180;
	mul.lo.s32 	%r313, %r312, 65537;
	sub.s32 	%r411, %r311, %r313;

$L__BB0_55:
	add.s32 	%r315, %r411, %r70;
	mul.wide.u32 	%rd181, %r315, -65535;
	shr.u64 	%rd182, %rd181, 48;
	cvt.u32.u64 	%r316, %rd182;
	mul.lo.s32 	%r317, %r316, 65537;
	sub.s32 	%r318, %r315, %r317;
	st.global.u32 	[%rd15], %r318;
	add.s32 	%r319, %r70, 65537;
	sub.s32 	%r320, %r319, %r411;
	mul.wide.u32 	%rd183, %r320, -65535;
	shr.u64 	%rd184, %rd183, 48;
	cvt.u32.u64 	%r321, %rd184;
	mul.lo.s32 	%r322, %r321, 65537;
	sub.s32 	%r323, %r320, %r322;
	st.global.u32 	[%rd16], %r323;
	add.s32 	%r75, %r69, 1;
	shr.u32 	%r324, %r75, %r36;
	shl.b32 	%r325, %r324, %r403;
	and.b32  	%r326, %r75, %r39;
	add.s32 	%r327, %r325, %r326;
	mul.wide.u32 	%rd185, %r327, 4;
	add.s64 	%rd17, %rd4, %rd185;
	ld.global.u32 	%r76, [%rd17];
	add.s32 	%r328, %r327, %r37;
	mul.wide.u32 	%rd186, %r328, 4;
	add.s64 	%rd18, %rd4, %rd186;
	add.s32 	%r329, %r40, %r326;
	mul.wide.u32 	%rd187, %r329, 4;
	add.s64 	%rd188, %rd3, %rd187;
	ld.global.u32 	%r77, [%rd18];
	setp.eq.s32 	%p45, %r77, 65536;
	ld.global.u32 	%r78, [%rd188];
	setp.eq.s32 	%p46, %r78, 65536;
	and.pred  	%p47, %p45, %p46;
	@%p47 bra 	$L__BB0_57;

	mul.lo.s32 	%r330, %r78, %r77;
	mul.wide.u32 	%rd189, %r330, -65535;
	shr.u64 	%rd190, %rd189, 48;
	cvt.u32.u64 	%r331, %rd190;
	mul.lo.s32 	%r332, %r331, 65537;
	sub.s32 	%r412, %r330, %r332;

$L__BB0_57:
	add.s32 	%r333, %r412, %r76;
	mul.wide.u32 	%rd191, %r333, -65535;
	shr.u64 	%rd192, %rd191, 48;
	cvt.u32.u64 	%r334, %rd192;
	mul.lo.s32 	%r335, %r334, 65537;
	sub.s32 	%r336, %r333, %r335;
	st.global.u32 	[%rd17], %r336;
	add.s32 	%r337, %r76, 65537;
	sub.s32 	%r338, %r337, %r412;
	mul.wide.u32 	%rd193, %r338, -65535;
	shr.u64 	%rd194, %rd193, 48;
	cvt.u32.u64 	%r339, %rd194;
	mul.lo.s32 	%r340, %r339, 65537;
	sub.s32 	%r341, %r338, %r340;
	st.global.u32 	[%rd18], %r341;
	add.s32 	%r407, %r75, 1;
	setp.lt.u32 	%p48, %r407, %r6;
	@%p48 bra 	$L__BB0_49;

$L__BB0_58:
	bar.sync 	0;
	setp.lt.u32 	%p49, %r403, %r138;
	@%p49 bra 	$L__BB0_36;

$L__BB0_59:
	and.b32  	%r342, %r139, 1;
	setp.eq.b32 	%p51, %r342, 1;
	not.pred 	%p52, %p51;
	or.pred  	%p53, %p52, %p1;
	@%p53 bra 	$L__BB0_86;

	cvta.to.global.u64 	%rd195, %rd30;
	mul.wide.u32 	%rd196, %r2, 4;
	add.s64 	%rd19, %rd195, %rd196;
	sub.s32 	%r343, %r6, %r4;
	and.b32  	%r415, %r343, 3;
	setp.eq.s32 	%p54, %r415, 0;
	mov.u32 	%r418, %r4;
	@%p54 bra 	$L__BB0_67;

	add.s32 	%r413, %r5, %r4;
	mov.u32 	%r418, %r4;

$L__BB0_62:
	.pragma "nounroll";
	mul.wide.u32 	%rd197, %r418, 4;
	add.s64 	%rd20, %rd4, %rd197;
	ld.global.u32 	%r87, [%rd20];
	setp.eq.s32 	%p55, %r87, 65536;
	ld.global.u32 	%r88, [%rd19];
	setp.eq.s32 	%p56, %r88, 65536;
	and.pred  	%p57, %p55, %p56;
	mov.u32 	%r417, 1;
	mov.u32 	%r416, %r417;
	@%p57 bra 	$L__BB0_64;

	mul.lo.s32 	%r345, %r88, %r87;
	mul.wide.u32 	%rd198, %r345, -65535;
	shr.u64 	%rd199, %rd198, 48;
	cvt.u32.u64 	%r346, %rd199;
	mul.lo.s32 	%r347, %r346, 65537;
	sub.s32 	%r416, %r345, %r347;

$L__BB0_64:
	st.global.u32 	[%rd20], %r416;
	mul.wide.u32 	%rd200, %r413, 4;
	add.s64 	%rd21, %rd4, %rd200;
	ld.global.u32 	%r91, [%rd21];
	setp.eq.s32 	%p58, %r91, 65536;
	ld.global.u32 	%r92, [%rd19];
	setp.eq.s32 	%p59, %r92, 65536;
	and.pred  	%p60, %p58, %p59;
	@%p60 bra 	$L__BB0_66;

	mul.lo.s32 	%r349, %r92, %r91;
	mul.wide.u32 	%rd201, %r349, -65535;
	shr.u64 	%rd202, %rd201, 48;
	cvt.u32.u64 	%r350, %rd202;
	mul.lo.s32 	%r351, %r350, 65537;
	sub.s32 	%r417, %r349, %r351;

$L__BB0_66:
	st.global.u32 	[%rd21], %r417;
	add.s32 	%r418, %r418, 1;
	add.s32 	%r413, %r413, 1;
	add.s32 	%r415, %r415, -1;
	setp.ne.s32 	%p61, %r415, 0;
	@%p61 bra 	$L__BB0_62;

$L__BB0_67:
	not.b32 	%r352, %r6;
	mov.u32 	%r353, -2;
	sub.s32 	%r354, %r353, %r4;
	sub.s32 	%r355, %r354, %r352;
	setp.lt.u32 	%p62, %r355, 3;
	@%p62 bra 	$L__BB0_86;

	add.s32 	%r356, %r418, %r5;
	add.s32 	%r419, %r356, 3;
	add.s32 	%r100, %r5, 1;

$L__BB0_69:
	mul.wide.u32 	%rd203, %r418, 4;
	add.s64 	%rd22, %rd4, %rd203;
	ld.global.u32 	%r103, [%rd22];
	setp.eq.s32 	%p63, %r103, 65536;
	ld.global.u32 	%r104, [%rd19];
	setp.eq.s32 	%p64, %r104, 65536;
	and.pred  	%p65, %p63, %p64;
	mov.u32 	%r422, 1;
	mov.u32 	%r421, %r422;
	@%p65 bra 	$L__BB0_71;

	mul.lo.s32 	%r358, %r104, %r103;
	mul.wide.u32 	%rd204, %r358, -65535;
	shr.u64 	%rd205, %rd204, 48;
	cvt.u32.u64 	%r359, %rd205;
	mul.lo.s32 	%r360, %r359, 65537;
	sub.s32 	%r421, %r358, %r360;

$L__BB0_71:
	st.global.u32 	[%rd22], %r421;
	add.s32 	%r362, %r5, %r418;
	mul.wide.u32 	%rd206, %r362, 4;
	add.s64 	%rd23, %rd4, %rd206;
	ld.global.u32 	%r107, [%rd23];
	setp.eq.s32 	%p66, %r107, 65536;
	ld.global.u32 	%r108, [%rd19];
	setp.eq.s32 	%p67, %r108, 65536;
	and.pred  	%p68, %p66, %p67;
	@%p68 bra 	$L__BB0_73;

	mul.lo.s32 	%r363, %r108, %r107;
	mul.wide.u32 	%rd207, %r363, -65535;
	shr.u64 	%rd208, %rd207, 48;
	cvt.u32.u64 	%r364, %rd208;
	mul.lo.s32 	%r365, %r364, 65537;
	sub.s32 	%r422, %r363, %r365;

$L__BB0_73:
	st.global.u32 	[%rd23], %r422;
	add.s32 	%r367, %r418, 1;
	mov.u32 	%r424, 1;
	mul.wide.u32 	%rd209, %r367, 4;
	add.s64 	%rd24, %rd4, %rd209;
	ld.global.u32 	%r111, [%rd24];
	setp.eq.s32 	%p69, %r111, 65536;
	ld.global.u32 	%r112, [%rd19];
	setp.eq.s32 	%p70, %r112, 65536;
	and.pred  	%p71, %p69, %p70;
	mov.u32 	%r423, %r424;
	@%p71 bra 	$L__BB0_75;

	mul.lo.s32 	%r368, %r112, %r111;
	mul.wide.u32 	%rd210, %r368, -65535;
	shr.u64 	%rd211, %rd210, 48;
	cvt.u32.u64 	%r369, %rd211;
	mul.lo.s32 	%r370, %r369, 65537;
	sub.s32 	%r423, %r368, %r370;

$L__BB0_75:
	st.global.u32 	[%rd24], %r423;
	add.s32 	%r372, %r100, %r418;
	mul.wide.u32 	%rd212, %r372, 4;
	add.s64 	%rd25, %rd4, %rd212;
	ld.global.u32 	%r115, [%rd25];
	setp.eq.s32 	%p72, %r115, 65536;
	ld.global.u32 	%r116, [%rd19];
	setp.eq.s32 	%p73, %r116, 65536;
	and.pred  	%p74, %p72, %p73;
	@%p74 bra 	$L__BB0_77;

	mul.lo.s32 	%r373, %r116, %r115;
	mul.wide.u32 	%rd213, %r373, -65535;
	shr.u64 	%rd214, %rd213, 48;
	cvt.u32.u64 	%r374, %rd214;
	mul.lo.s32 	%r375, %r374, 65537;
	sub.s32 	%r424, %r373, %r375;

$L__BB0_77:
	st.global.u32 	[%rd25], %r424;
	add.s32 	%r377, %r418, 2;
	mul.wide.u32 	%rd215, %r377, 4;
	add.s64 	%rd26, %rd4, %rd215;
	ld.global.u32 	%r119, [%rd26];
	setp.eq.s32 	%p75, %r119, 65536;
	ld.global.u32 	%r120, [%rd19];
	setp.eq.s32 	%p76, %r120, 65536;
	and.pred  	%p77, %p75, %p76;
	mov.u32 	%r426, 1;
	mov.u32 	%r425, %r426;
	@%p77 bra 	$L__BB0_79;

	mul.lo.s32 	%r378, %r120, %r119;
	mul.wide.u32 	%rd216, %r378, -65535;
	shr.u64 	%rd217, %rd216, 48;
	cvt.u32.u64 	%r379, %rd217;
	mul.lo.s32 	%r380, %r379, 65537;
	sub.s32 	%r425, %r378, %r380;

$L__BB0_79:
	st.global.u32 	[%rd26], %r425;
	add.s32 	%r382, %r419, -1;
	mul.wide.u32 	%rd218, %r382, 4;
	add.s64 	%rd27, %rd4, %rd218;
	ld.global.u32 	%r123, [%rd27];
	setp.eq.s32 	%p78, %r123, 65536;
	ld.global.u32 	%r124, [%rd19];
	setp.eq.s32 	%p79, %r124, 65536;
	and.pred  	%p80, %p78, %p79;
	@%p80 bra 	$L__BB0_81;

	mul.lo.s32 	%r383, %r124, %r123;
	mul.wide.u32 	%rd219, %r383, -65535;
	shr.u64 	%rd220, %rd219, 48;
	cvt.u32.u64 	%r384, %rd220;
	mul.lo.s32 	%r385, %r384, 65537;
	sub.s32 	%r426, %r383, %r385;

$L__BB0_81:
	st.global.u32 	[%rd27], %r426;
	add.s32 	%r387, %r418, 3;
	mul.wide.u32 	%rd221, %r387, 4;
	add.s64 	%rd28, %rd4, %rd221;
	ld.global.u32 	%r127, [%rd28];
	setp.eq.s32 	%p81, %r127, 65536;
	ld.global.u32 	%r128, [%rd19];
	setp.eq.s32 	%p82, %r128, 65536;
	and.pred  	%p83, %p81, %p82;
	mov.u32 	%r428, 1;
	mov.u32 	%r427, %r428;
	@%p83 bra 	$L__BB0_83;

	mul.lo.s32 	%r388, %r128, %r127;
	mul.wide.u32 	%rd222, %r388, -65535;
	shr.u64 	%rd223, %rd222, 48;
	cvt.u32.u64 	%r389, %rd223;
	mul.lo.s32 	%r390, %r389, 65537;
	sub.s32 	%r427, %r388, %r390;

$L__BB0_83:
	st.global.u32 	[%rd28], %r427;
	mul.wide.u32 	%rd224, %r419, 4;
	add.s64 	%rd29, %rd4, %rd224;
	ld.global.u32 	%r131, [%rd29];
	setp.eq.s32 	%p84, %r131, 65536;
	ld.global.u32 	%r132, [%rd19];
	setp.eq.s32 	%p85, %r132, 65536;
	and.pred  	%p86, %p84, %p85;
	@%p86 bra 	$L__BB0_85;

	mul.lo.s32 	%r392, %r132, %r131;
	mul.wide.u32 	%rd225, %r392, -65535;
	shr.u64 	%rd226, %rd225, 48;
	cvt.u32.u64 	%r393, %rd226;
	mul.lo.s32 	%r394, %r393, 65537;
	sub.s32 	%r428, %r392, %r394;

$L__BB0_85:
	st.global.u32 	[%rd29], %r428;
	add.s32 	%r419, %r419, 4;
	add.s32 	%r418, %r418, 4;
	setp.lt.u32 	%p87, %r418, %r6;
	@%p87 bra 	$L__BB0_69;

$L__BB0_86:
	ret;

}
	// .globl	_Z14g_vector_mul_iPjS_S_jj
.visible .entry _Z14g_vector_mul_iPjS_S_jj(
	.param .u64 _Z14g_vector_mul_iPjS_S_jj_param_0,
	.param .u64 _Z14g_vector_mul_iPjS_S_jj_param_1,
	.param .u64 _Z14g_vector_mul_iPjS_S_jj_param_2,
	.param .u32 _Z14g_vector_mul_iPjS_S_jj_param_3,
	.param .u32 _Z14g_vector_mul_iPjS_S_jj_param_4
)
{
	.reg .pred 	%p<21>;
	.reg .b32 	%r<80>;
	.reg .b64 	%rd<47>;


	ld.param.u64 	%rd9, [_Z14g_vector_mul_iPjS_S_jj_param_0];
	ld.param.u64 	%rd10, [_Z14g_vector_mul_iPjS_S_jj_param_1];
	ld.param.u64 	%rd11, [_Z14g_vector_mul_iPjS_S_jj_param_2];
	ld.param.u32 	%r31, [_Z14g_vector_mul_iPjS_S_jj_param_3];
	ld.param.u32 	%r32, [_Z14g_vector_mul_iPjS_S_jj_param_4];
	cvta.to.global.u64 	%rd1, %rd11;
	cvta.to.global.u64 	%rd2, %rd10;
	cvta.to.global.u64 	%rd3, %rd9;
	mov.u32 	%r33, %ntid.x;
	mov.u32 	%r34, %ctaid.x;
	mov.u32 	%r35, %tid.x;
	mad.lo.s32 	%r36, %r34, %r33, %r35;
	mul.lo.s32 	%r1, %r36, %r32;
	add.s32 	%r37, %r1, %r32;
	min.u32 	%r2, %r37, %r31;
	setp.ge.u32 	%p1, %r1, %r2;
	@%p1 bra 	$L__BB1_17;

	sub.s32 	%r38, %r2, %r1;
	and.b32  	%r72, %r38, 3;
	setp.eq.s32 	%p2, %r72, 0;
	mov.u32 	%r74, %r1;
	@%p2 bra 	$L__BB1_6;

	mov.u32 	%r74, %r1;

$L__BB1_3:
	.pragma "nounroll";
	cvt.u64.u32 	%rd4, %r74;
	mul.wide.u32 	%rd12, %r74, 4;
	add.s64 	%rd13, %rd3, %rd12;
	add.s64 	%rd14, %rd2, %rd12;
	ld.global.u32 	%r6, [%rd13];
	setp.eq.s32 	%p3, %r6, 65536;
	ld.global.u32 	%r7, [%rd14];
	setp.eq.s32 	%p4, %r7, 65536;
	and.pred  	%p5, %p3, %p4;
	mov.u32 	%r73, 1;
	@%p5 bra 	$L__BB1_5;

	mul.lo.s32 	%r40, %r7, %r6;
	mul.wide.u32 	%rd15, %r40, -65535;
	shr.u64 	%rd16, %rd15, 48;
	cvt.u32.u64 	%r41, %rd16;
	mul.lo.s32 	%r42, %r41, 65537;
	sub.s32 	%r73, %r40, %r42;

$L__BB1_5:
	shl.b64 	%rd17, %rd4, 2;
	add.s64 	%rd18, %rd1, %rd17;
	st.global.u32 	[%rd18], %r73;
	cvt.u32.u64 	%r43, %rd4;
	add.s32 	%r74, %r43, 1;
	add.s32 	%r72, %r72, -1;
	setp.ne.s32 	%p6, %r72, 0;
	@%p6 bra 	$L__BB1_3;

$L__BB1_6:
	mov.u32 	%r44, -2;
	sub.s32 	%r45, %r44, %r1;
	not.b32 	%r46, %r2;
	sub.s32 	%r47, %r45, %r46;
	setp.lt.u32 	%p7, %r47, 3;
	@%p7 bra 	$L__BB1_17;

$L__BB1_8:
	cvt.u64.u32 	%rd5, %r74;
	mul.wide.u32 	%rd19, %r74, 4;
	add.s64 	%rd20, %rd3, %rd19;
	add.s64 	%rd21, %rd2, %rd19;
	ld.global.u32 	%r14, [%rd20];
	setp.eq.s32 	%p8, %r14, 65536;
	ld.global.u32 	%r15, [%rd21];
	setp.eq.s32 	%p9, %r15, 65536;
	and.pred  	%p10, %p8, %p9;
	mov.u32 	%r77, 1;
	mov.u32 	%r76, %r77;
	@%p10 bra 	$L__BB1_10;

	mul.lo.s32 	%r49, %r15, %r14;
	mul.wide.u32 	%rd22, %r49, -65535;
	shr.u64 	%rd23, %rd22, 48;
	cvt.u32.u64 	%r50, %rd23;
	mul.lo.s32 	%r51, %r50, 65537;
	sub.s32 	%r76, %r49, %r51;

$L__BB1_10:
	shl.b64 	%rd24, %rd5, 2;
	add.s64 	%rd25, %rd1, %rd24;
	st.global.u32 	[%rd25], %r76;
	cvt.u32.u64 	%r53, %rd5;
	add.s32 	%r54, %r53, 1;
	cvt.u64.u32 	%rd6, %r54;
	mul.wide.u32 	%rd26, %r54, 4;
	add.s64 	%rd27, %rd3, %rd26;
	add.s64 	%rd28, %rd2, %rd26;
	ld.global.u32 	%r18, [%rd27];
	setp.eq.s32 	%p11, %r18, 65536;
	ld.global.u32 	%r19, [%rd28];
	setp.eq.s32 	%p12, %r19, 65536;
	and.pred  	%p13, %p11, %p12;
	@%p13 bra 	$L__BB1_12;

	mul.lo.s32 	%r55, %r19, %r18;
	mul.wide.u32 	%rd29, %r55, -65535;
	shr.u64 	%rd30, %rd29, 48;
	cvt.u32.u64 	%r56, %rd30;
	mul.lo.s32 	%r57, %r56, 65537;
	sub.s32 	%r77, %r55, %r57;

$L__BB1_12:
	shl.b64 	%rd31, %rd6, 2;
	add.s64 	%rd32, %rd1, %rd31;
	st.global.u32 	[%rd32], %r77;
	add.s32 	%r60, %r53, 2;
	cvt.u64.u32 	%rd7, %r60;
	mul.wide.u32 	%rd33, %r60, 4;
	add.s64 	%rd34, %rd3, %rd33;
	add.s64 	%rd35, %rd2, %rd33;
	ld.global.u32 	%r22, [%rd34];
	setp.eq.s32 	%p14, %r22, 65536;
	ld.global.u32 	%r23, [%rd35];
	setp.eq.s32 	%p15, %r23, 65536;
	and.pred  	%p16, %p14, %p15;
	mov.u32 	%r79, 1;
	mov.u32 	%r78, %r79;
	@%p16 bra 	$L__BB1_14;

	mul.lo.s32 	%r61, %r23, %r22;
	mul.wide.u32 	%rd36, %r61, -65535;
	shr.u64 	%rd37, %rd36, 48;
	cvt.u32.u64 	%r62, %rd37;
	mul.lo.s32 	%r63, %r62, 65537;
	sub.s32 	%r78, %r61, %r63;

$L__BB1_14:
	shl.b64 	%rd38, %rd7, 2;
	add.s64 	%rd39, %rd1, %rd38;
	st.global.u32 	[%rd39], %r78;
	add.s32 	%r66, %r53, 3;
	cvt.u64.u32 	%rd8, %r66;
	mul.wide.u32 	%rd40, %r66, 4;
	add.s64 	%rd41, %rd3, %rd40;
	add.s64 	%rd42, %rd2, %rd40;
	ld.global.u32 	%r26, [%rd41];
	setp.eq.s32 	%p17, %r26, 65536;
	ld.global.u32 	%r27, [%rd42];
	setp.eq.s32 	%p18, %r27, 65536;
	and.pred  	%p19, %p17, %p18;
	@%p19 bra 	$L__BB1_16;

	mul.lo.s32 	%r67, %r27, %r26;
	mul.wide.u32 	%rd43, %r67, -65535;
	shr.u64 	%rd44, %rd43, 48;
	cvt.u32.u64 	%r68, %rd44;
	mul.lo.s32 	%r69, %r68, 65537;
	sub.s32 	%r79, %r67, %r69;

$L__BB1_16:
	shl.b64 	%rd45, %rd8, 2;
	add.s64 	%rd46, %rd1, %rd45;
	st.global.u32 	[%rd46], %r79;
	add.s32 	%r74, %r53, 4;
	setp.lt.u32 	%p20, %r74, %r2;
	@%p20 bra 	$L__BB1_8;

$L__BB1_17:
	ret;

}
	// .globl	_Z6g_fillPjjjj
.visible .entry _Z6g_fillPjjjj(
	.param .u64 _Z6g_fillPjjjj_param_0,
	.param .u32 _Z6g_fillPjjjj_param_1,
	.param .u32 _Z6g_fillPjjjj_param_2,
	.param .u32 _Z6g_fillPjjjj_param_3
)
{
	.reg .pred 	%p<6>;
	.reg .b32 	%r<31>;
	.reg .b64 	%rd<13>;


	ld.param.u64 	%rd2, [_Z6g_fillPjjjj_param_0];
	ld.param.u32 	%r11, [_Z6g_fillPjjjj_param_1];
	ld.param.u32 	%r12, [_Z6g_fillPjjjj_param_2];
	ld.param.u32 	%r13, [_Z6g_fillPjjjj_param_3];
	cvta.to.global.u64 	%rd1, %rd2;
	mov.u32 	%r14, %ntid.x;
	mov.u32 	%r15, %ctaid.x;
	mov.u32 	%r16, %tid.x;
	mad.lo.s32 	%r17, %r15, %r14, %r16;
	mul.lo.s32 	%r1, %r17, %r13;
	add.s32 	%r18, %r1, %r13;
	min.u32 	%r2, %r18, %r12;
	setp.ge.u32 	%p1, %r1, %r2;
	@%p1 bra 	$L__BB2_7;

	sub.s32 	%r19, %r2, %r1;
	and.b32  	%r28, %r19, 3;
	setp.eq.s32 	%p2, %r28, 0;
	mov.u32 	%r29, %r1;
	@%p2 bra 	$L__BB2_4;

	mov.u32 	%r29, %r1;

$L__BB2_3:
	.pragma "nounroll";
	mul.wide.u32 	%rd3, %r29, 4;
	add.s64 	%rd4, %rd1, %rd3;
	st.global.u32 	[%rd4], %r11;
	add.s32 	%r29, %r29, 1;
	add.s32 	%r28, %r28, -1;
	setp.ne.s32 	%p3, %r28, 0;
	@%p3 bra 	$L__BB2_3;

$L__BB2_4:
	mov.u32 	%r20, -2;
	sub.s32 	%r21, %r20, %r1;
	not.b32 	%r22, %r2;
	sub.s32 	%r23, %r21, %r22;
	setp.lt.u32 	%p4, %r23, 3;
	@%p4 bra 	$L__BB2_7;

$L__BB2_6:
	mul.wide.u32 	%rd5, %r29, 4;
	add.s64 	%rd6, %rd1, %rd5;
	st.global.u32 	[%rd6], %r11;
	add.s32 	%r24, %r29, 1;
	mul.wide.u32 	%rd7, %r24, 4;
	add.s64 	%rd8, %rd1, %rd7;
	st.global.u32 	[%rd8], %r11;
	add.s32 	%r25, %r29, 2;
	mul.wide.u32 	%rd9, %r25, 4;
	add.s64 	%rd10, %rd1, %rd9;
	st.global.u32 	[%rd10], %r11;
	add.s32 	%r26, %r29, 3;
	mul.wide.u32 	%rd11, %r26, 4;
	add.s64 	%rd12, %rd1, %rd11;
	st.global.u32 	[%rd12], %r11;
	add.s32 	%r29, %r29, 4;
	setp.lt.u32 	%p5, %r29, %r2;
	@%p5 bra 	$L__BB2_6;

$L__BB2_7:
	ret;

}
	// .globl	_Z12g_poly_derivPjS_j
.visible .entry _Z12g_poly_derivPjS_j(
	.param .u64 _Z12g_poly_derivPjS_j_param_0,
	.param .u64 _Z12g_poly_derivPjS_j_param_1,
	.param .u32 _Z12g_poly_derivPjS_j_param_2
)
{
	.reg .pred 	%p<21>;
	.reg .b32 	%r<72>;
	.reg .b64 	%rd<38>;


	ld.param.u64 	%rd6, [_Z12g_poly_derivPjS_j_param_0];
	ld.param.u64 	%rd7, [_Z12g_poly_derivPjS_j_param_1];
	ld.param.u32 	%r29, [_Z12g_poly_derivPjS_j_param_2];
	cvta.to.global.u64 	%rd1, %rd7;
	cvta.to.global.u64 	%rd2, %rd6;
	mov.u32 	%r30, %ntid.x;
	mov.u32 	%r31, %ctaid.x;
	mov.u32 	%r32, %tid.x;
	mad.lo.s32 	%r33, %r31, %r30, %r32;
	mul.lo.s32 	%r67, %r33, %r29;
	add.s32 	%r2, %r67, %r29;
	setp.ge.u32 	%p1, %r67, %r2;
	@%p1 bra 	$L__BB3_17;

	and.b32  	%r63, %r29, 3;
	setp.eq.s32 	%p2, %r63, 0;
	@%p2 bra 	$L__BB3_6;

	mov.u32 	%r62, %r67;

$L__BB3_3:
	.pragma "nounroll";
	add.s32 	%r67, %r62, 1;
	mov.u32 	%r64, 1;
	mul.wide.u32 	%rd8, %r67, 4;
	add.s64 	%rd9, %rd2, %rd8;
	ld.global.u32 	%r7, [%rd9];
	setp.eq.s32 	%p3, %r7, 65536;
	setp.eq.s32 	%p4, %r67, 65536;
	and.pred  	%p5, %p4, %p3;
	@%p5 bra 	$L__BB3_5;

	mul.lo.s32 	%r35, %r7, %r67;
	mul.wide.u32 	%rd10, %r35, -65535;
	shr.u64 	%rd11, %rd10, 48;
	cvt.u32.u64 	%r36, %rd11;
	mul.lo.s32 	%r37, %r36, 65537;
	sub.s32 	%r64, %r35, %r37;

$L__BB3_5:
	mul.wide.u32 	%rd12, %r62, 4;
	add.s64 	%rd13, %rd1, %rd12;
	st.global.u32 	[%rd13], %r64;
	add.s32 	%r63, %r63, -1;
	setp.ne.s32 	%p6, %r63, 0;
	mov.u32 	%r62, %r67;
	@%p6 bra 	$L__BB3_3;

$L__BB3_6:
	add.s32 	%r38, %r29, -1;
	setp.lt.u32 	%p7, %r38, 3;
	@%p7 bra 	$L__BB3_17;

	mov.u32 	%r39, 65535;
	sub.s32 	%r66, %r39, %r67;

$L__BB3_8:
	add.s32 	%r41, %r67, 1;
	mov.u32 	%r69, 1;
	cvt.u64.u32 	%rd3, %r41;
	mul.wide.u32 	%rd14, %r41, 4;
	add.s64 	%rd15, %rd2, %rd14;
	ld.global.u32 	%r15, [%rd15];
	setp.eq.s32 	%p8, %r15, 65536;
	setp.eq.s32 	%p9, %r66, 0;
	and.pred  	%p10, %p9, %p8;
	mov.u32 	%r68, %r69;
	@%p10 bra 	$L__BB3_10;

	cvt.u32.u64 	%r42, %rd3;
	mul.lo.s32 	%r43, %r15, %r42;
	mul.wide.u32 	%rd16, %r43, -65535;
	shr.u64 	%rd17, %rd16, 48;
	cvt.u32.u64 	%r44, %rd17;
	mul.lo.s32 	%r45, %r44, 65537;
	sub.s32 	%r68, %r43, %r45;

$L__BB3_10:
	mul.wide.u32 	%rd18, %r67, 4;
	add.s64 	%rd19, %rd1, %rd18;
	st.global.u32 	[%rd19], %r68;
	add.s32 	%r47, %r67, 2;
	cvt.u64.u32 	%rd4, %r47;
	mul.wide.u32 	%rd20, %r47, 4;
	add.s64 	%rd21, %rd2, %rd20;
	ld.global.u32 	%r18, [%rd21];
	setp.eq.s32 	%p11, %r18, 65536;
	setp.eq.s32 	%p12, %r66, 1;
	and.pred  	%p13, %p12, %p11;
	@%p13 bra 	$L__BB3_12;

	cvt.u32.u64 	%r48, %rd4;
	mul.lo.s32 	%r49, %r18, %r48;
	mul.wide.u32 	%rd22, %r49, -65535;
	shr.u64 	%rd23, %rd22, 48;
	cvt.u32.u64 	%r50, %rd23;
	mul.lo.s32 	%r51, %r50, 65537;
	sub.s32 	%r69, %r49, %r51;

$L__BB3_12:
	shl.b64 	%rd24, %rd3, 2;
	add.s64 	%rd25, %rd1, %rd24;
	st.global.u32 	[%rd25], %r69;
	add.s32 	%r53, %r67, 3;
	cvt.u64.u32 	%rd5, %r53;
	mul.wide.u32 	%rd26, %r53, 4;
	add.s64 	%rd27, %rd2, %rd26;
	ld.global.u32 	%r21, [%rd27];
	setp.eq.s32 	%p14, %r21, 65536;
	setp.eq.s32 	%p15, %r66, 2;
	and.pred  	%p16, %p15, %p14;
	mov.u32 	%r71, 1;
	mov.u32 	%r70, %r71;
	@%p16 bra 	$L__BB3_14;

	cvt.u32.u64 	%r54, %rd5;
	mul.lo.s32 	%r55, %r21, %r54;
	mul.wide.u32 	%rd28, %r55, -65535;
	shr.u64 	%rd29, %rd28, 48;
	cvt.u32.u64 	%r56, %rd29;
	mul.lo.s32 	%r57, %r56, 65537;
	sub.s32 	%r70, %r55, %r57;

$L__BB3_14:
	shl.b64 	%rd30, %rd4, 2;
	add.s64 	%rd31, %rd1, %rd30;
	st.global.u32 	[%rd31], %r70;
	add.s32 	%r67, %r67, 4;
	mul.wide.u32 	%rd32, %r67, 4;
	add.s64 	%rd33, %rd2, %rd32;
	ld.global.u32 	%r25, [%rd33];
	setp.eq.s32 	%p17, %r25, 65536;
	setp.eq.s32 	%p18, %r66, 3;
	and.pred  	%p19, %p18, %p17;
	@%p19 bra 	$L__BB3_16;

	mul.lo.s32 	%r59, %r25, %r67;
	mul.wide.u32 	%rd34, %r59, -65535;
	shr.u64 	%rd35, %rd34, 48;
	cvt.u32.u64 	%r60, %rd35;
	mul.lo.s32 	%r61, %r60, 65537;
	sub.s32 	%r71, %r59, %r61;

$L__BB3_16:
	shl.b64 	%rd36, %rd5, 2;
	add.s64 	%rd37, %rd1, %rd36;
	st.global.u32 	[%rd37], %r71;
	add.s32 	%r66, %r66, -4;
	setp.lt.u32 	%p20, %r67, %r2;
	@%p20 bra 	$L__BB3_8;

$L__BB3_17:
	ret;

}
	// .globl	_Z10g_build_n1PjS_S_S_S_j
.visible .entry _Z10g_build_n1PjS_S_S_S_j(
	.param .u64 _Z10g_build_n1PjS_S_S_S_j_param_0,
	.param .u64 _Z10g_build_n1PjS_S_S_S_j_param_1,
	.param .u64 _Z10g_build_n1PjS_S_S_S_j_param_2,
	.param .u64 _Z10g_build_n1PjS_S_S_S_j_param_3,
	.param .u64 _Z10g_build_n1PjS_S_S_S_j_param_4,
	.param .u32 _Z10g_build_n1PjS_S_S_S_j_param_5
)
{
	.reg .pred 	%p<21>;
	.reg .b32 	%r<84>;
	.reg .b64 	%rd<71>;


	ld.param.u64 	%rd11, [_Z10g_build_n1PjS_S_S_S_j_param_0];
	ld.param.u64 	%rd12, [_Z10g_build_n1PjS_S_S_S_j_param_1];
	ld.param.u64 	%rd13, [_Z10g_build_n1PjS_S_S_S_j_param_2];
	ld.param.u64 	%rd14, [_Z10g_build_n1PjS_S_S_S_j_param_3];
	ld.param.u64 	%rd15, [_Z10g_build_n1PjS_S_S_S_j_param_4];
	ld.param.u32 	%r31, [_Z10g_build_n1PjS_S_S_S_j_param_5];
	cvta.to.global.u64 	%rd1, %rd11;
	cvta.to.global.u64 	%rd2, %rd15;
	cvta.to.global.u64 	%rd3, %rd12;
	cvta.to.global.u64 	%rd4, %rd13;
	cvta.to.global.u64 	%rd5, %rd14;
	mov.u32 	%r32, %ntid.x;
	mov.u32 	%r33, %ctaid.x;
	mov.u32 	%r34, %tid.x;
	mad.lo.s32 	%r35, %r33, %r32, %r34;
	mul.lo.s32 	%r78, %r35, %r31;
	add.s32 	%r2, %r78, %r31;
	setp.ge.u32 	%p1, %r78, %r2;
	@%p1 bra 	$L__BB4_17;

	and.b32  	%r76, %r31, 3;
	setp.eq.s32 	%p2, %r76, 0;
	@%p2 bra 	$L__BB4_6;

$L__BB4_3:
	.pragma "nounroll";
	cvt.u64.u32 	%rd6, %r78;
	mul.wide.u32 	%rd16, %r78, 4;
	add.s64 	%rd17, %rd5, %rd16;
	add.s64 	%rd18, %rd4, %rd16;
	ld.global.u32 	%r37, [%rd18];
	mul.wide.u32 	%rd19, %r37, 4;
	add.s64 	%rd20, %rd3, %rd19;
	ld.global.u32 	%r38, [%rd20];
	mul.wide.u32 	%rd21, %r38, 4;
	add.s64 	%rd22, %rd2, %rd21;
	ld.global.u32 	%r6, [%rd17];
	setp.eq.s32 	%p3, %r6, 65536;
	ld.global.u32 	%r7, [%rd22];
	setp.eq.s32 	%p4, %r7, 65536;
	and.pred  	%p5, %p3, %p4;
	mov.u32 	%r77, 1;
	@%p5 bra 	$L__BB4_5;

	mul.lo.s32 	%r39, %r7, %r6;
	mul.wide.u32 	%rd23, %r39, -65535;
	shr.u64 	%rd24, %rd23, 48;
	cvt.u32.u64 	%r40, %rd24;
	mul.lo.s32 	%r41, %r40, 65537;
	sub.s32 	%r77, %r39, %r41;

$L__BB4_5:
	shl.b64 	%rd25, %rd6, 2;
	add.s64 	%rd26, %rd1, %rd25;
	st.global.u32 	[%rd26], %r77;
	cvt.u32.u64 	%r42, %rd6;
	add.s32 	%r78, %r42, 1;
	add.s32 	%r76, %r76, -1;
	setp.ne.s32 	%p6, %r76, 0;
	@%p6 bra 	$L__BB4_3;

$L__BB4_6:
	add.s32 	%r43, %r31, -1;
	setp.lt.u32 	%p7, %r43, 3;
	@%p7 bra 	$L__BB4_17;

$L__BB4_8:
	cvt.u64.u32 	%rd7, %r78;
	mul.wide.u32 	%rd27, %r78, 4;
	add.s64 	%rd28, %rd5, %rd27;
	add.s64 	%rd29, %rd4, %rd27;
	ld.global.u32 	%r45, [%rd29];
	mul.wide.u32 	%rd30, %r45, 4;
	add.s64 	%rd31, %rd3, %rd30;
	ld.global.u32 	%r46, [%rd31];
	mul.wide.u32 	%rd32, %r46, 4;
	add.s64 	%rd33, %rd2, %rd32;
	ld.global.u32 	%r14, [%rd28];
	setp.eq.s32 	%p8, %r14, 65536;
	ld.global.u32 	%r15, [%rd33];
	setp.eq.s32 	%p9, %r15, 65536;
	and.pred  	%p10, %p8, %p9;
	mov.u32 	%r81, 1;
	mov.u32 	%r80, %r81;
	@%p10 bra 	$L__BB4_10;

	mul.lo.s32 	%r47, %r15, %r14;
	mul.wide.u32 	%rd34, %r47, -65535;
	shr.u64 	%rd35, %rd34, 48;
	cvt.u32.u64 	%r48, %rd35;
	mul.lo.s32 	%r49, %r48, 65537;
	sub.s32 	%r80, %r47, %r49;

$L__BB4_10:
	shl.b64 	%rd36, %rd7, 2;
	add.s64 	%rd37, %rd1, %rd36;
	st.global.u32 	[%rd37], %r80;
	cvt.u32.u64 	%r51, %rd7;
	add.s32 	%r52, %r51, 1;
	cvt.u64.u32 	%rd8, %r52;
	mul.wide.u32 	%rd38, %r52, 4;
	add.s64 	%rd39, %rd5, %rd38;
	add.s64 	%rd40, %rd4, %rd38;
	ld.global.u32 	%r53, [%rd40];
	mul.wide.u32 	%rd41, %r53, 4;
	add.s64 	%rd42, %rd3, %rd41;
	ld.global.u32 	%r54, [%rd42];
	mul.wide.u32 	%rd43, %r54, 4;
	add.s64 	%rd44, %rd2, %rd43;
	ld.global.u32 	%r18, [%rd39];
	setp.eq.s32 	%p11, %r18, 65536;
	ld.global.u32 	%r19, [%rd44];
	setp.eq.s32 	%p12, %r19, 65536;
	and.pred  	%p13, %p11, %p12;
	@%p13 bra 	$L__BB4_12;

	mul.lo.s32 	%r55, %r19, %r18;
	mul.wide.u32 	%rd45, %r55, -65535;
	shr.u64 	%rd46, %rd45, 48;
	cvt.u32.u64 	%r56, %rd46;
	mul.lo.s32 	%r57, %r56, 65537;
	sub.s32 	%r81, %r55, %r57;

$L__BB4_12:
	shl.b64 	%rd47, %rd8, 2;
	add.s64 	%rd48, %rd1, %rd47;
	st.global.u32 	[%rd48], %r81;
	add.s32 	%r60, %r51, 2;
	cvt.u64.u32 	%rd9, %r60;
	mul.wide.u32 	%rd49, %r60, 4;
	add.s64 	%rd50, %rd5, %rd49;
	add.s64 	%rd51, %rd4, %rd49;
	ld.global.u32 	%r61, [%rd51];
	mul.wide.u32 	%rd52, %r61, 4;
	add.s64 	%rd53, %rd3, %rd52;
	ld.global.u32 	%r62, [%rd53];
	mul.wide.u32 	%rd54, %r62, 4;
	add.s64 	%rd55, %rd2, %rd54;
	ld.global.u32 	%r22, [%rd50];
	setp.eq.s32 	%p14, %r22, 65536;
	ld.global.u32 	%r23, [%rd55];
	setp.eq.s32 	%p15, %r23, 65536;
	and.pred  	%p16, %p14, %p15;
	mov.u32 	%r83, 1;
	mov.u32 	%r82, %r83;
	@%p16 bra 	$L__BB4_14;

	mul.lo.s32 	%r63, %r23, %r22;
	mul.wide.u32 	%rd56, %r63, -65535;
	shr.u64 	%rd57, %rd56, 48;
	cvt.u32.u64 	%r64, %rd57;
	mul.lo.s32 	%r65, %r64, 65537;
	sub.s32 	%r82, %r63, %r65;

$L__BB4_14:
	shl.b64 	%rd58, %rd9, 2;
	add.s64 	%rd59, %rd1, %rd58;
	st.global.u32 	[%rd59], %r82;
	add.s32 	%r68, %r51, 3;
	cvt.u64.u32 	%rd10, %r68;
	mul.wide.u32 	%rd60, %r68, 4;
	add.s64 	%rd61, %rd5, %rd60;
	add.s64 	%rd62, %rd4, %rd60;
	ld.global.u32 	%r69, [%rd62];
	mul.wide.u32 	%rd63, %r69, 4;
	add.s64 	%rd64, %rd3, %rd63;
	ld.global.u32 	%r70, [%rd64];
	mul.wide.u32 	%rd65, %r70, 4;
	add.s64 	%rd66, %rd2, %rd65;
	ld.global.u32 	%r26, [%rd61];
	setp.eq.s32 	%p17, %r26, 65536;
	ld.global.u32 	%r27, [%rd66];
	setp.eq.s32 	%p18, %r27, 65536;
	and.pred  	%p19, %p17, %p18;
	@%p19 bra 	$L__BB4_16;

	mul.lo.s32 	%r71, %r27, %r26;
	mul.wide.u32 	%rd67, %r71, -65535;
	shr.u64 	%rd68, %rd67, 48;
	cvt.u32.u64 	%r72, %rd68;
	mul.lo.s32 	%r73, %r72, 65537;
	sub.s32 	%r83, %r71, %r73;

$L__BB4_16:
	shl.b64 	%rd69, %rd10, 2;
	add.s64 	%rd70, %rd1, %rd69;
	st.global.u32 	[%rd70], %r83;
	add.s32 	%r78, %r51, 4;
	setp.lt.u32 	%p20, %r78, %r2;
	@%p20 bra 	$L__BB4_8;

$L__BB4_17:
	ret;

}
	// .globl	_Z10g_build_n2PjS_S_j
.visible .entry _Z10g_build_n2PjS_S_j(
	.param .u64 _Z10g_build_n2PjS_S_j_param_0,
	.param .u64 _Z10g_build_n2PjS_S_j_param_1,
	.param .u64 _Z10g_build_n2PjS_S_j_param_2,
	.param .u32 _Z10g_build_n2PjS_S_j_param_3
)
{
	.reg .pred 	%p<6>;
	.reg .b32 	%r<34>;
	.reg .b64 	%rd<32>;


	ld.param.u64 	%rd4, [_Z10g_build_n2PjS_S_j_param_0];
	ld.param.u64 	%rd5, [_Z10g_build_n2PjS_S_j_param_1];
	ld.param.u64 	%rd6, [_Z10g_build_n2PjS_S_j_param_2];
	ld.param.u32 	%r11, [_Z10g_build_n2PjS_S_j_param_3];
	cvta.to.global.u64 	%rd1, %rd4;
	cvta.to.global.u64 	%rd2, %rd6;
	cvta.to.global.u64 	%rd3, %rd5;
	mov.u32 	%r12, %ntid.x;
	mov.u32 	%r13, %ctaid.x;
	mov.u32 	%r14, %tid.x;
	mad.lo.s32 	%r15, %r13, %r12, %r14;
	mul.lo.s32 	%r32, %r15, %r11;
	add.s32 	%r2, %r32, %r11;
	setp.ge.u32 	%p1, %r32, %r2;
	@%p1 bra 	$L__BB5_7;

	and.b32  	%r31, %r11, 3;
	setp.eq.s32 	%p2, %r31, 0;
	@%p2 bra 	$L__BB5_4;

$L__BB5_3:
	.pragma "nounroll";
	mul.wide.u32 	%rd7, %r32, 4;
	add.s64 	%rd8, %rd3, %rd7;
	ld.global.u32 	%r16, [%rd8];
	add.s64 	%rd9, %rd2, %rd7;
	ld.global.u32 	%r17, [%rd9];
	mul.wide.u32 	%rd10, %r17, 4;
	add.s64 	%rd11, %rd1, %rd10;
	st.global.u32 	[%rd11], %r16;
	add.s32 	%r32, %r32, 1;
	add.s32 	%r31, %r31, -1;
	setp.ne.s32 	%p3, %r31, 0;
	@%p3 bra 	$L__BB5_3;

$L__BB5_4:
	add.s32 	%r18, %r11, -1;
	setp.lt.u32 	%p4, %r18, 3;
	@%p4 bra 	$L__BB5_7;

$L__BB5_6:
	mul.wide.u32 	%rd12, %r32, 4;
	add.s64 	%rd13, %rd3, %rd12;
	ld.global.u32 	%r19, [%rd13];
	add.s64 	%rd14, %rd2, %rd12;
	ld.global.u32 	%r20, [%rd14];
	mul.wide.u32 	%rd15, %r20, 4;
	add.s64 	%rd16, %rd1, %rd15;
	st.global.u32 	[%rd16], %r19;
	add.s32 	%r21, %r32, 1;
	mul.wide.u32 	%rd17, %r21, 4;
	add.s64 	%rd18, %rd3, %rd17;
	ld.global.u32 	%r22, [%rd18];
	add.s64 	%rd19, %rd2, %rd17;
	ld.global.u32 	%r23, [%rd19];
	mul.wide.u32 	%rd20, %r23, 4;
	add.s64 	%rd21, %rd1, %rd20;
	st.global.u32 	[%rd21], %r22;
	add.s32 	%r24, %r32, 2;
	mul.wide.u32 	%rd22, %r24, 4;
	add.s64 	%rd23, %rd3, %rd22;
	ld.global.u32 	%r25, [%rd23];
	add.s64 	%rd24, %rd2, %rd22;
	ld.global.u32 	%r26, [%rd24];
	mul.wide.u32 	%rd25, %r26, 4;
	add.s64 	%rd26, %rd1, %rd25;
	st.global.u32 	[%rd26], %r25;
	add.s32 	%r27, %r32, 3;
	mul.wide.u32 	%rd27, %r27, 4;
	add.s64 	%rd28, %rd3, %rd27;
	ld.global.u32 	%r28, [%rd28];
	add.s64 	%rd29, %rd2, %rd27;
	ld.global.u32 	%r29, [%rd29];
	mul.wide.u32 	%rd30, %r29, 4;
	add.s64 	%rd31, %rd1, %rd30;
	st.global.u32 	[%rd31], %r28;
	add.s32 	%r32, %r32, 4;
	setp.lt.u32 	%p5, %r32, %r2;
	@%p5 bra 	$L__BB5_6;

$L__BB5_7:
	ret;

}
	// .globl	_Z10g_build_n3PjS_j
.visible .entry _Z10g_build_n3PjS_j(
	.param .u64 _Z10g_build_n3PjS_j_param_0,
	.param .u64 _Z10g_build_n3PjS_j_param_1,
	.param .u32 _Z10g_build_n3PjS_j_param_2
)
{
	.reg .pred 	%p<6>;
	.reg .b32 	%r<51>;
	.reg .b64 	%rd<32>;


	ld.param.u64 	%rd3, [_Z10g_build_n3PjS_j_param_0];
	ld.param.u64 	%rd4, [_Z10g_build_n3PjS_j_param_1];
	ld.param.u32 	%r11, [_Z10g_build_n3PjS_j_param_2];
	cvta.to.global.u64 	%rd1, %rd3;
	cvta.to.global.u64 	%rd2, %rd4;
	mov.u32 	%r12, %ntid.x;
	mov.u32 	%r13, %ctaid.x;
	mov.u32 	%r14, %tid.x;
	mad.lo.s32 	%r15, %r13, %r12, %r14;
	mul.lo.s32 	%r50, %r15, %r11;
	add.s32 	%r2, %r50, %r11;
	setp.ge.u32 	%p1, %r50, %r2;
	@%p1 bra 	$L__BB6_7;

	and.b32  	%r48, %r11, 3;
	setp.eq.s32 	%p2, %r48, 0;
	@%p2 bra 	$L__BB6_4;

	mov.u32 	%r47, %r50;

$L__BB6_3:
	.pragma "nounroll";
	add.s32 	%r50, %r47, 1;
	mul.wide.u32 	%rd5, %r50, 4;
	add.s64 	%rd6, %rd2, %rd5;
	ld.global.u32 	%r16, [%rd6];
	mov.u32 	%r17, 65537;
	sub.s32 	%r18, %r17, %r16;
	mul.wide.u32 	%rd7, %r18, -65535;
	shr.u64 	%rd8, %rd7, 48;
	cvt.u32.u64 	%r19, %rd8;
	mul.lo.s32 	%r20, %r19, 65537;
	sub.s32 	%r21, %r18, %r20;
	mul.wide.u32 	%rd9, %r47, 4;
	add.s64 	%rd10, %rd1, %rd9;
	st.global.u32 	[%rd10], %r21;
	add.s32 	%r48, %r48, -1;
	setp.ne.s32 	%p3, %r48, 0;
	mov.u32 	%r47, %r50;
	@%p3 bra 	$L__BB6_3;

$L__BB6_4:
	add.s32 	%r22, %r11, -1;
	setp.lt.u32 	%p4, %r22, 3;
	@%p4 bra 	$L__BB6_7;

$L__BB6_6:
	add.s32 	%r23, %r50, 1;
	mul.wide.u32 	%rd11, %r23, 4;
	add.s64 	%rd12, %rd2, %rd11;
	ld.global.u32 	%r24, [%rd12];
	mov.u32 	%r25, 65537;
	sub.s32 	%r26, %r25, %r24;
	mul.wide.u32 	%rd13, %r26, -65535;
	shr.u64 	%rd14, %rd13, 48;
	cvt.u32.u64 	%r27, %rd14;
	mul.lo.s32 	%r28, %r27, 65537;
	sub.s32 	%r29, %r26, %r28;
	mul.wide.u32 	%rd15, %r50, 4;
	add.s64 	%rd16, %rd1, %rd15;
	st.global.u32 	[%rd16], %r29;
	add.s32 	%r30, %r50, 2;
	mul.wide.u32 	%rd17, %r30, 4;
	add.s64 	%rd18, %rd2, %rd17;
	ld.global.u32 	%r31, [%rd18];
	sub.s32 	%r32, %r25, %r31;
	mul.wide.u32 	%rd19, %r32, -65535;
	shr.u64 	%rd20, %rd19, 48;
	cvt.u32.u64 	%r33, %rd20;
	mul.lo.s32 	%r34, %r33, 65537;
	sub.s32 	%r35, %r32, %r34;
	add.s64 	%rd21, %rd1, %rd11;
	st.global.u32 	[%rd21], %r35;
	add.s32 	%r36, %r50, 3;
	mul.wide.u32 	%rd22, %r36, 4;
	add.s64 	%rd23, %rd2, %rd22;
	ld.global.u32 	%r37, [%rd23];
	sub.s32 	%r38, %r25, %r37;
	mul.wide.u32 	%rd24, %r38, -65535;
	shr.u64 	%rd25, %rd24, 48;
	cvt.u32.u64 	%r39, %rd25;
	mul.lo.s32 	%r40, %r39, 65537;
	sub.s32 	%r41, %r38, %r40;
	add.s64 	%rd26, %rd1, %rd17;
	st.global.u32 	[%rd26], %r41;
	add.s32 	%r50, %r50, 4;
	mul.wide.u32 	%rd27, %r50, 4;
	add.s64 	%rd28, %rd2, %rd27;
	ld.global.u32 	%r42, [%rd28];
	sub.s32 	%r43, %r25, %r42;
	mul.wide.u32 	%rd29, %r43, -65535;
	shr.u64 	%rd30, %rd29, 48;
	cvt.u32.u64 	%r44, %rd30;
	mul.lo.s32 	%r45, %r44, 65537;
	sub.s32 	%r46, %r43, %r45;
	add.s64 	%rd31, %rd1, %rd22;
	st.global.u32 	[%rd31], %r46;
	setp.lt.u32 	%p5, %r50, %r2;
	@%p5 bra 	$L__BB6_6;

$L__BB6_7:
	ret;

}

